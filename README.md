# RAG Agent - Document Q&A System

An AI agent that answers questions from uploaded PDF documents using Retrieval Augmented Generation (RAG) with LangGraph orchestration.

## ğŸ¯ Features

- **Document Upload**: Process and index PDF documents locally
- **Semantic Search**: Uses sentence-transformers for embeddings + ChromaDB for vector storage
- **Agent Orchestration**: LangGraph-powered agent with reasoning, tool calling, and validation
- **Strict Guardrails**: Only answers from provided documents with source citations
- **Memory**: Maintains conversation history for contextual follow-ups
- **100% Local & Free**: Runs entirely on your machine using Ollama (no API costs)

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER (CLI Interface)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENT ORCHESTRATOR                        â”‚
â”‚                      (LangGraph)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Reasoning â”‚â†’ â”‚Retrieval â”‚â†’ â”‚Validationâ”‚â†’ â”‚ Answer   â”‚   â”‚
â”‚  â”‚  Node    â”‚  â”‚  Node    â”‚  â”‚  Node    â”‚  â”‚  Node    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DOCUMENT      â”‚  â”‚   VECTOR DB     â”‚  â”‚     LLM       â”‚
â”‚  PROCESSOR     â”‚  â”‚   (ChromaDB)    â”‚  â”‚   (Ollama)    â”‚
â”‚                â”‚  â”‚                 â”‚  â”‚               â”‚
â”‚ â€¢ PDF Parser   â”‚  â”‚ â€¢ Embeddings    â”‚  â”‚ â€¢ llama3.2:3b â”‚
â”‚ â€¢ Chunker      â”‚  â”‚ â€¢ Similarity    â”‚  â”‚ â€¢ Local       â”‚
â”‚ â€¢ Metadata     â”‚  â”‚   Search        â”‚  â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Flow

```
START
  â†“
[REASONING NODE]
  - Analyzes user question
  - Decides action: RETRIEVE / ANSWER / INSUFFICIENT
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           â”‚
[RETRIEVE]              [ANSWER from history]
  â†“                         â†“
[RETRIEVAL NODE]           END
  - Semantic search
  - Fetch relevant chunks
  â†“
[VALIDATION NODE]
  - Check if docs sufficient
  - Guardrail enforcement
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           â”‚
[SUFFICIENT]          [INSUFFICIENT]
  â†“                         â†“
[ANSWER NODE]         [INSUFFICIENT NODE]
  - Generate response      - Explain limitation
  - Add citations          - Suggest alternatives
  â†“                         â†“
END                        END
```

## ğŸš€ Setup

### Prerequisites

1. **Python 3.9+**
2. **Ollama** - Install from [ollama.ai](https://ollama.ai)

### Installation Steps

1. **Clone/Download the repository**

```bash
cd rag-agent
```

2. **Create virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Install and start Ollama**

```bash
# Start Ollama server
ollama serve

# In another terminal, pull the model
ollama pull llama3.2:3b
```

5. **Verify setup**

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Should show llama3.2:3b in the list
```

## ğŸ“– Usage

### Interactive Mode (Recommended)

```bash
python cli.py
```

Commands in interactive mode:
- Type any question to ask the agent
- `upload <path>` - Upload a PDF document
- `list` - Show uploaded documents
- `stats` - Show database statistics
- `help` - Show help message
- `quit` or `exit` - Exit

### Command-Line Mode

```bash
# Upload a document
python cli.py --upload path/to/document.pdf

# Ask a question
python cli.py --question "What is the main topic?"

# Upload and ask in one command
python cli.py --upload document.pdf --question "What is the revenue?"

# List documents
python cli.py --list

# Show stats
python cli.py --stats
```

### Example Session

```bash
$ python cli.py

ğŸš€ Initializing RAG Agent...
âœ… RAG Agent initialized successfully!

======================================================================
INTERACTIVE MODE
======================================================================
Commands:
  - Ask any question about your documents
  - 'upload <path>' - Upload a new document
  - 'list' - List uploaded documents
  - 'stats' - Show database statistics
  - 'quit' or 'exit' - Exit
======================================================================

You: upload financial_report.pdf

ğŸ“„ Uploading document: financial_report.pdf
âœ… Document uploaded: financial_report.pdf
âš™ï¸  Processing document (extracting text, chunking, embedding)...
âœ… Extracted 45 chunks from document
ğŸ” Adding to vector database...
âœ… Added 45 chunks to vector database

ğŸ“Š Database stats:
   Total chunks: 45
   Documents: 1
   Sources: financial_report.pdf

You: What was the Q1 revenue?

â“ Question: What was the Q1 revenue?
ğŸ¤” Thinking...

======================================================================
ğŸ’¡ ANSWER:
======================================================================
According to the financial report, Q1 revenue was $150 million, 
representing a 20% increase compared to Q1 of the previous year. 
This growth was primarily driven by expansion in the North American 
market and increased enterprise sales.

[Source: financial_report.pdf, Page 3]
======================================================================

You: How does this compare to Q2?

â“ Question: How does this compare to Q2?
ğŸ¤” Thinking...

======================================================================
ğŸ’¡ ANSWER:
======================================================================
Q2 revenue reached $165 million, showing an increase of $15 million 
(10% growth) compared to Q1's $150 million. [Source: financial_report.pdf, 
Page 5]
======================================================================

You: quit

ğŸ‘‹ Goodbye!
```

## ğŸ§© Project Structure

```
rag-agent/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ graph.py           # LangGraph agent definition
â”‚   â”‚   â”œâ”€â”€ nodes.py           # Agent node functions
â”‚   â”‚   â”œâ”€â”€ state.py           # State schema
â”‚   â”‚   â””â”€â”€ prompts.py         # Prompt templates
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ vector_store.py    # ChromaDB integration
â”‚   â”‚   â”œâ”€â”€ embeddings.py      # Sentence-transformers
â”‚   â”‚   â””â”€â”€ retriever.py       # Retrieval interface
â”‚   â”‚
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py      # PDF text extraction
â”‚   â”‚   â”œâ”€â”€ chunker.py         # Text chunking
â”‚   â”‚   â””â”€â”€ document_manager.py # Document pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ ollama_client.py   # Ollama API client
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py          # Configuration
â”‚       â””â”€â”€ logger.py          # Logging utilities
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/               # Uploaded PDFs
â”‚   â””â”€â”€ chroma_db/             # Vector database
â”‚
â”œâ”€â”€ cli.py                     # CLI interface
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Edit `src/utils/config.py` to customize:

- **LLM Model**: Change `OLLAMA_MODEL` (e.g., `mistral:7b`, `qwen2.5:7b`)
- **Chunk Size**: Adjust `CHUNK_SIZE` (default: 512)
- **Retrieval**: Modify `TOP_K_DOCUMENTS` (default: 5)
- **Temperature**: Change `OLLAMA_TEMPERATURE` (default: 0.1)
- **Logging**: Set `LOG_LEVEL` (DEBUG, INFO, WARNING, ERROR)

## ğŸ›¡ï¸ Guardrails & Safety

The agent implements multiple layers of guardrails:

1. **Reasoning Guardrail**: Agent decides if it should retrieve or decline
2. **Validation Guardrail**: Checks if retrieved docs contain sufficient info
3. **Prompt Guardrail**: Instructions to LLM to only use provided context
4. **Citation Requirement**: All answers must include source references

## ğŸ§  How It Works

### 1. Document Processing Pipeline

```python
PDF Upload â†’ Text Extraction â†’ Chunking â†’ Embedding â†’ Vector DB
```

- PDFs are parsed page by page
- Text is split into 512-character chunks with 50-char overlap
- Each chunk gets an embedding via sentence-transformers
- Stored in ChromaDB with metadata (source, page number)

### 2. Agent Reasoning Loop

```python
Question â†’ Reasoning â†’ Tool Decision â†’ Retrieval â†’ Validation â†’ Answer
```

The agent:
1. **Reasons** about the question (new query vs follow-up)
2. **Decides** whether to retrieve documents
3. **Retrieves** relevant chunks from vector DB (if needed)
4. **Validates** if documents contain enough information
5. **Generates** answer with citations OR states "cannot answer"

### 3. Tool Calling

The agent has access to:
- **Document Retrieval Tool**: Searches vector database
- **Validation Tool**: Checks answer feasibility

The LLM decides when and how to use these tools based on the question.

## ğŸ“Š Logging

Detailed logging tracks every step:

```
====================================================
AGENT STEP: REASONING
====================================================
question: What is the revenue?
iteration: 1
====================================================

[Reasoning output...]

====================================================
AGENT STEP: RETRIEVAL
====================================================
query: revenue Q1 Q2
====================================================

[Retrieved documents...]
```

## ğŸ“ Assignment Requirements Coverage

âœ… **Agent Design & Orchestration**: LangGraph with state machine
âœ… **RAG**: Semantic search with ChromaDB + sentence-transformers  
âœ… **Memory**: Conversation history in state
âœ… **Tool Calling**: Retrieval tool with agent decision-making
âœ… **Guardrails**: Multi-layer validation and safety controls
âœ… **Real-world Integration**: File system (PDFs), vector DB, local LLM
âœ… **Advanced Tech**: LangGraph, modern RAG patterns, validation loops

## ğŸ› Troubleshooting

### "Cannot connect to Ollama"
- Ensure Ollama is running: `ollama serve`
- Check if running on correct port: `curl http://localhost:11434/api/tags`

### "Model not found"
- Pull the model: `ollama pull llama3.2:3b`
- Verify: `ollama list`

### "No text extracted from PDF"
- PDF might be scanned images (needs OCR)
- Try a different PDF with selectable text
- Check PDF isn't corrupted

### Slow performance
- First run downloads embedding model (~100MB)
- Reduce `CHUNK_SIZE` in config
- Use smaller model: `llama3.2:1b`

## ğŸ“ Notes

- **First run**: Downloads sentence-transformer model (~100MB)
- **Memory usage**: ~2-4GB RAM depending on model
- **Vector DB**: Persistent across runs (stored in `data/chroma_db/`)
- **Sessions**: Each CLI run creates a new session (no persistence between runs yet)

## ğŸš§ Future Enhancements

- [ ] Session persistence (save chat history)
- [ ] Multi-document reasoning
- [ ] Table extraction from PDFs
- [ ] Image/chart analysis (with vision models)
- [ ] Query rewriting for better retrieval
- [ ] Re-ranking retrieved documents
- [ ] Streamlit web UI
- [ ] Support for more document types (Word, HTML, etc.)

## ğŸ“œ License

MIT License - Feel free to use and modify!

## ğŸ™ Acknowledgments

- **LangGraph**: For agent orchestration framework
- **Ollama**: For local LLM hosting
- **ChromaDB**: For vector storage
- **sentence-transformers**: For embeddings

---

**Built with â¤ï¸ for production-ready LLM applications**
